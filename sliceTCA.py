# -*- coding: utf-8 -*-
"""sliceTCA.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1dtUWECSK-KRS8UIgYMWjlrxGctWc46xo

# 1. Import Dataset
"""

# install the slicetca package
!pip install git+https://github.com/arthur-pe/slicetca.git
# import necessary modules
import torch
import sys
import numpy as np
import scipy.io as sio
import slicetca
from matplotlib import pyplot as plt
import time



# Set the device
device = 'cuda' if torch.cuda.is_available() else 'cpu'
print(device);

from google.colab import drive
drive.mount('/content/drive')

!python -V

input_path = '/content/drive/Othercomputers/Lenovo Laptop/temporal_criticality_of_latent_results/TCA/Archive/BLA/tensor_data.mat'

mat = sio.loadmat(input_path)
mat.keys()

# ————————————————
# Load data: pre-stimulus
# ————————————————
mat = sio.loadmat(input_path)
X = mat['pre_data'].astype(np.float32)     #shape (N, T,K)
# shape (K, N, T)
X = np.transpose(X, (2, 0, 1))
# your_data is a numpy array of shape (trials, neurons, time).
data = torch.tensor(X, dtype=torch.float, device=device)
K, N, T = X.shape  # Get dimensions of X
print(data.shape)

# ————————————————
# Load data: post-stimulus
# ————————————————
X_post = mat['post_data'].astype(np.float32)     #shape (N, T,K)
# shape (K, N, T)
X_post = np.transpose(X_post, (2, 0, 1))
# your_data is a numpy array of shape (trials, neurons, time).
data_post = torch.tensor(X_post, dtype=torch.float, device=device)
print(data_post.shape)

"""# 2. Model Selection: We will use cross-validation to see for each factor how many components we need to use."""

# ranges to explore
R_neuron_list = [3, 10, 20, 32]
R_trial_list  = [8, 30, 40, 60]
R_time_list   = [16, 51, 102, 153]  # often 0–2 is enough

print("Testing different rank combinations to find the best model...")
model_losses = {}

# Create a simpler version first - just fit each model once and record the loss
for i, (Rne, Rtr, Rti) in enumerate([(r1, r2, r3) for r1 in R_neuron_list
                                     for r2 in R_trial_list
                                     for r3 in R_time_list]):
    print(f"Testing combination {i+1}/{len(R_neuron_list) * len(R_trial_list) * len(R_time_list)}: ({Rne}, {Rtr}, {Rti})")

    try:
        start_time = time.time()
        # Start with a small number of iterations to test quickly
        _, model = slicetca.decompose(
            data,
            (Rne, Rti, Rtr),  # Note: order matches your slicetca.decompose calls (neuron, time, trial)
            max_iter=500
        )

        # Record the final loss
        if hasattr(model, 'losses') and len(model.losses) > 0:
            final_loss = model.losses[-1]
            model_losses[(Rne, Rtr, Rti)] = final_loss
            print(f"  Final loss: {final_loss:.6f}, Time: {time.time() - start_time:.2f}s")
        else:
            print("  No losses recorded")

    except Exception as e:
        print(f"  Error: {e}")
        continue

# Find the best parameters
if model_losses:
    best = min(model_losses, key=model_losses.get)
    print("\nResults:")
    print(f"Best model based on final loss: {best} with loss {model_losses[best]:.6f}")

    # Train final model with best parameters
    Rne, Rtr, Rti = best
    print(f"\nTraining final model with ranks: Neuron={Rne}, Trial={Rtr}, Time={Rti}")

    try:
        # Train the final model with more iterations
        components, final_model = slicetca.decompose(
            data,
            (Rne, Rti, Rtr),  # Note ordering (neuron, time, trial)
            max_iter=5000
        )

        # Plot loss curve
        if hasattr(final_model, 'losses'):
            plt.figure(figsize=(8, 4))
            plt.plot(np.arange(len(final_model.losses)), final_model.losses, 'k')
            plt.xlabel('Iterations')
            plt.ylabel('Mean Squared Error')
            plt.title(f'Loss Curve for Best Model (R_neuron={Rne}, R_trial={Rtr}, R_time={Rti})')
            plt.tight_layout()
            plt.show()

        # Try to plot using slicetca.plot
        try:
            print("\nSliceTCA Decomposition: BLA Condition - Pre-stimulus (Best Model)")
            slicetca.plot(final_model)
            plt.show()
        except Exception as e:
            print(f"Could not use slicetca.plot: {e}")

            # Manual plotting as fallback
            if hasattr(final_model, 'vectors'):
                vectors = final_model.vectors
                if len(vectors) == 3:
                    U, V, W = vectors

                    plt.figure(figsize=(15, 10))

                    # Plot neuron factors
                    plt.subplot(3, 1, 1)
                    for r in range(min(5, U.shape[1])):
                        plt.plot(np.arange(U.shape[0]), U[:, r].cpu().numpy(), label=f'Comp {r+1}')
                    plt.title('Neuron Factors')
                    plt.legend()

                    # Plot time factors
                    plt.subplot(3, 1, 2)
                    for r in range(min(5, V.shape[1])):
                        plt.plot(np.arange(V.shape[0]), V[:, r].cpu().numpy(), label=f'Comp {r+1}')
                    plt.title('Time Factors')
                    plt.legend()

                    # Plot trial factors
                    plt.subplot(3, 1, 3)
                    for r in range(min(5, W.shape[1])):
                        plt.plot(np.arange(W.shape[0]), W[:, r].cpu().numpy(), label=f'Comp {r+1}')
                    plt.title('Trial Factors')
                    plt.legend()

                    plt.tight_layout()
                    plt.show()

    except Exception as e:
        print(f"Error with final model: {e}")
else:
    print("No valid results were obtained. Try different parameters.")

print("\n\nProcessing post-stimulus data with the same best parameters")
try:
    X_post = mat['post_data'].astype(np.float32)
    X_post = np.transpose(X_post, (2, 0, 1))
    data_post = torch.tensor(X_post, dtype=torch.float, device=device)
    print(f"Post-stimulus data shape: {data_post.shape}")

    # Use the same best parameters
    components_post, model_post = slicetca.decompose(
        data_post,
        (Rne, Rti, Rtr),
        max_iter=5000
    )

    print("SliceTCA Decomposition: BLA Condition - Post-stimulus")
    try:
        slicetca.plot(model_post)
        plt.show()
    except Exception as e:
        print(f"Could not use slicetca.plot for post-stimulus: {e}")

        # Manual plotting
        if hasattr(model_post, 'vectors'):
            vectors = model_post.vectors
            if len(vectors) == 3:
                U, V, W = vectors

                plt.figure(figsize=(15, 10))

                # Plot neuron factors
                plt.subplot(3, 1, 1)
                for r in range(min(5, U.shape[1])):
                    plt.plot(np.arange(U.shape[0]), U[:, r].cpu().numpy(), label=f'Comp {r+1}')
                plt.title('Post-stimulus Neuron Factors')
                plt.legend()

                # Plot time factors
                plt.subplot(3, 1, 2)
                for r in range(min(5, V.shape[1])):
                    plt.plot(np.arange(V.shape[0]), V[:, r].cpu().numpy(), label=f'Comp {r+1}')
                plt.title('Post-stimulus Time Factors')
                plt.legend()

                # Plot trial factors
                plt.subplot(3, 1, 3)
                for r in range(min(5, W.shape[1])):
                    plt.plot(np.arange(W.shape[0]), W[:, r].cpu().numpy(), label=f'Comp {r+1}')
                plt.title('Post-stimulus Trial Factors')
                plt.legend()

                plt.tight_layout()
                plt.show()

except Exception as e:
    print(f"Error processing post-stimulus data: {e}")





"""# 3. Run Model with optimized factor numbers"""

# ————————————————
# Hyperparameters
# ————————————————
R_neuron = 20    # e.g. start with 2 neuron‐slicing comps
R_trial  = 40    # e.g. 4 trial‐slicing comps
R_time   = 100    # e.g. 1 time‐slicing comp

# ————————————————
# Initialize and fit model
# ————————————————

components, model = slicetca.decompose(data,
                    (R_neuron,R_time,R_trial),
                    max_iter=5000)

# For a not positive decomposition, we apply uniqueness constraints
model = slicetca.invariance(model)

plt.figure(figsize=(4,3), dpi=100)
plt.plot(np.arange(00,len(model.losses)), model.losses, 'k')
plt.xlabel('iterations')
plt.ylabel('mean squared error')
plt.xlim(0,len(model.losses))
plt.tight_layout()

print("SliceTCA Decomposition: BLA Condition - Pre-stimulus")
slicetca.plot(model)
# plt.suptitle( fontsize=14)
plt.show()

model

# ————————————————
# Save results
# ————————————————
# sio.savemat(sys.argv[2], {
    'U': U, 'A': A,
    'V': V, 'B': B,
    'W': W, 'C': C,
    'reconstruction': model.reconstruct()
# })
# print("sliceTCA complete. Results saved to", sys.argv[2])

components_post, model_post = slicetca.decompose(data_post,
                    (R_neuron,R_time,R_trial),
                    max_iter=5000)

# For a not positive decomposition, we apply uniqueness constraints
model_post = slicetca.invariance(model_post)

print("SliceTCA Decomposition: BLA Condition - post-stimulus")
slicetca.plot(model_post)
plt.show()

plt.figure(figsize=(4,3), dpi=100)
plt.plot(np.arange(1000,len(model_post.losses)), model_post.losses[1000:], 'k')
plt.xlabel('iterations')
plt.ylabel('mean squared error')
plt.xlim(0,len(model_post.losses))
plt.tight_layout()